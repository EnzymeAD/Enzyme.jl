<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>AutoDiff API · Enzyme.jl</title><script data-outdated-warner src="../../assets/warner.js"></script><link rel="canonical" href="https://enzyme.mit.edu/julia/generated/autodiff/"/><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.045/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/5.15.4/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.13.24/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="../.."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="../../assets/documenter.js"></script><script src="../../siteinfo.js"></script><script src="../../../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="../../assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="../../assets/themeswap.js"></script><script src="https://plausible.io/js/plausible.js" data-domain="enzyme.mit.edu" defer></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href="../../"><img src="../../assets/logo.svg" alt="Enzyme.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href="../../">Enzyme.jl</a></span></div><form class="docs-search" action="../../search/"><input class="docs-search-query" id="documenter-search-query" name="q" type="text" placeholder="Search docs"/></form><ul class="docs-menu"><li><a class="tocitem" href="../../">Home</a></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="../box/">Box model</a></li><li class="is-active"><a class="tocitem" href>AutoDiff API</a><ul class="internal"><li class="toplevel"><a class="tocitem" href="#Defining-a-function"><span>Defining a function</span></a></li><li class="toplevel"><a class="tocitem" href="#Reverse-mode"><span>Reverse mode</span></a></li><li class="toplevel"><a class="tocitem" href="#Forward-mode"><span>Forward mode</span></a></li><li class="toplevel"><a class="tocitem" href="#Forward-over-reverse"><span>Forward over reverse</span></a></li><li class="toplevel"><a class="tocitem" href="#Vector-forward-over-reverse"><span>Vector forward over reverse</span></a></li></ul></li><li><a class="tocitem" href="../custom_rule/">Custom rules</a></li></ul></li><li><a class="tocitem" href="../../api/">API</a></li><li><a class="tocitem" href="../../pullbacks/">Implementing pullbacks</a></li><li><a class="tocitem" href="../../dev_docs/">For developers</a></li><li><a class="tocitem" href="../../internal_api/">Internal API</a></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><nav class="breadcrumb"><ul class="is-hidden-mobile"><li><a class="is-disabled">Examples</a></li><li class="is-active"><a href>AutoDiff API</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>AutoDiff API</a></li></ul></nav><div class="docs-right"><a class="docs-edit-link" href="https://github.com/EnzymeAD/Enzyme.jl/blob/main/examples/autodiff.jl#" title="Edit on GitHub"><span class="docs-icon fab"></span><span class="docs-label is-hidden-touch">Edit on GitHub</span></a><a class="docs-settings-button fas fa-cog" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-sidebar-button fa fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a></div></header><article class="content" id="documenter-page"><h1 id="AutoDiff-API"><a class="docs-heading-anchor" href="#AutoDiff-API">AutoDiff API</a><a id="AutoDiff-API-1"></a><a class="docs-heading-anchor-permalink" href="#AutoDiff-API" title="Permalink"></a></h1><p>The goal of this tutorial is to give users already familiar with automatic differentiation (AD) an overview of the Enzyme differentiation API for the following differentiation modes</p><ul><li>Reverse mode</li><li>Forward mode</li><li>Forward over reverse mode</li><li>Vector Forward over reverse mode</li></ul><h1 id="Defining-a-function"><a class="docs-heading-anchor" href="#Defining-a-function">Defining a function</a><a id="Defining-a-function-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-a-function" title="Permalink"></a></h1><p>Enzyme differentiates arbitrary multivariate vector functions as the most general case in automatic differentiation</p><p class="math-container">\[f: \mathbb{R}^n \rightarrow \mathbb{R}^m, y = f(x)\]</p><p>For simplicity we define a vector function with <span>$m=1$</span>. However, this tutorial can easily be applied to arbitrary <span>$m \in \mathbb{N}$</span>.</p><pre><code class="language-julia hljs">using Enzyme

function f(x::Array{Float64}, y::Array{Float64})
    y[1] = x[1] * x[1] + x[2] * x[1]
    return nothing
end;</code></pre><h1 id="Reverse-mode"><a class="docs-heading-anchor" href="#Reverse-mode">Reverse mode</a><a id="Reverse-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Reverse-mode" title="Permalink"></a></h1><p>The reverse model in AD is defined as</p><p class="math-container">\[\begin{aligned}
y &amp;= f(x) \\
\bar{x} &amp;= \bar{y} \cdot \nabla f(x)
\end{aligned}\]</p><p>bar denotes an adjoint variable. Note that executing an AD in reverse mode computes both <span>$y$</span> and the adjoint <span>$\bar{x}$</span>.</p><pre><code class="language-julia hljs">x  = [2.0, 2.0]
bx = [0.0, 0.0]
y  = [0.0]
by = [1.0];</code></pre><p>Enzyme stores the value and adjoint of a variable in an object of type <code>Duplicated</code> where the first element represent the value and the second the adjoint. Evaluating the reverse model using Enzyme is done via the following call.</p><pre><code class="language-julia hljs">Enzyme.autodiff(Reverse, f, Duplicated(x, bx), Duplicated(y, by));</code></pre><p>This yields the gradient of <code>f</code> in <code>bx</code> at point <code>x = [2.0, 2.0]</code>. <code>by</code> is called the seed and has to be set to <span>$1.0$</span> in order to compute the gradient. Let&#39;s save the gradient for later.</p><pre><code class="language-julia hljs">g = copy(bx)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 6.0
 2.0</code></pre><h1 id="Forward-mode"><a class="docs-heading-anchor" href="#Forward-mode">Forward mode</a><a id="Forward-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-mode" title="Permalink"></a></h1><p>The forward model in AD is defined as</p><p class="math-container">\[\begin{aligned}
y &amp;= f(x) \\
\dot{y} &amp;= \nabla f(x) \cdot \dot{x}
\end{aligned}\]</p><p>To obtain the first element of the gradient using the forward model we have to seed <span>$\dot{x}$</span> with <span>$\dot{x} = [1.0,0.0]$</span></p><pre><code class="language-julia hljs">x  = [2.0, 2.0]
dx = [1.0, 0.0]
y  = [0.0]
dy = [0.0];</code></pre><p>In the forward mode the second element of <code>Duplicated</code> stores the tangent.</p><pre><code class="language-julia hljs">Enzyme.autodiff(Forward, f, Duplicated(x, dx), Duplicated(y, dy));</code></pre><p>We can now verify that indeed the reverse mode and forward mode yield the same result for the first component of the gradient. Note that to acquire the full gradient one needs to execute the forward model a second time with the seed <code>dx</code> set to <code>[0.0,1.0]</code>.</p><p>Let&#39;s verify whether the reverse and forward model agree.</p><pre><code class="language-julia hljs">g[1] == dy[1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><h1 id="Forward-over-reverse"><a class="docs-heading-anchor" href="#Forward-over-reverse">Forward over reverse</a><a id="Forward-over-reverse-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-over-reverse" title="Permalink"></a></h1><p>The forward over reverse (FoR) model is obtained by applying the forward model to the reverse model using the chain rule for the product in the adjoint statement.</p><p class="math-container">\[\begin{aligned}
y &amp;= f(x) \\
\dot{y} &amp;= \nabla f(x) \cdot \dot{x} \\
\bar{x} &amp;= \bar{y} \cdot \nabla f(x) \\
\dot{\bar{x}} &amp;= \bar{y} \cdot \nabla^2 f(x) \cdot \dot{x} + \dot{\bar{y}} \cdot \nabla f(x)
\end{aligned}\]</p><p>To obtain the first column/row of the Hessian <span>$\nabla^2 f(x)$</span> we have to seed <span>$\dot{\bar{y}}$</span> with <span>$[0.0]$</span>, <span>$\bar{y}$</span> with <span>$[1.0]$</span> and <span>$\dot{x}$</span> with <span>$[1.0, 0.0]$</span>.</p><pre><code class="language-julia hljs">y = [0.0]
x = [2.0, 2.0]

dy = [0.0]
dx = [1.0, 0.0]

bx = [0.0, 0.0]
by = [1.0]
dbx = [0.0, 0.0]
dby = [0.0]

Enzyme.autodiff(
    Forward,
    (x,y) -&gt; Enzyme.autodiff_deferred(Reverse, f, x, y),
    Duplicated(Duplicated(x, bx), Duplicated(dx, dbx)),
    Duplicated(Duplicated(y, by), Duplicated(dy, dby)),
)</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">()</code></pre><p>The FoR model also computes the forward model from before, giving us again the first component of the gradient.</p><pre><code class="language-julia hljs">g[1] == dy[1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>In addition we now have the first row/column of the Hessian.</p><pre><code class="language-julia hljs">dbx[1] == 2.0
dbx[2] == 1.0</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><h1 id="Vector-forward-over-reverse"><a class="docs-heading-anchor" href="#Vector-forward-over-reverse">Vector forward over reverse</a><a id="Vector-forward-over-reverse-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-forward-over-reverse" title="Permalink"></a></h1><p>The vector FoR allows us to propagate several tangents at once through the second-order model by computing the derivative of the gradient at multiple points at once. We begin by defining a helper function for the gradient. Since we will not need the original results (stored in y), we can mark it DuplicatedNoNeed. Specifically, this will perform the following:</p><p class="math-container">\[\begin{aligned}
\b{x} &amp;= \bar{x} + \bar{y} \cdot \nabla f(x) \\
\bar{y} &amp;= 0
\begin{end}\]</p><pre><code class="language-julia hljs">function grad(x, dx, y, dy)
  Enzyme.autodiff_deferred(Reverse, f, Duplicated(x, dx), DuplicatedNoNeed(y, dy))
  nothing
end</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">grad (generic function with 1 method)</code></pre><p>To compute the conventional gradient, we would call this function with our given inputs, dy = [1.0], and dx = [0.0, 0.0]. Since y is not needed, we can just set it to an undef vector.</p><pre><code class="language-julia hljs">x = [2.0, 2.0]
y = Vector{Float64}(undef, 1)
dx = [0.0, 0.0]
dy = [1.0]

grad(x, dx, y, dy)</code></pre><p>dx now contains the gradient</p><pre><code class="language-julia hljs">@show dx</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">2-element Vector{Float64}:
 6.0
 2.0</code></pre><p>To compute the hessian, we need to take the dervative of this gradient function at every input. Following the same seeding strategy as before, we now seed both in the <code>vx[1]=[1.0, 0.0]</code> and <code>vx[2]=[0.0, 1.0]</code> direction. These tuples have to be put into a <code>BatchDuplicated</code> type. We then compute the forward mode derivative at all these points.</p><pre><code class="language-julia hljs">vx = ([1.0, 0.0], [0.0, 1.0])
hess = ([0.0, 0.0], [0.0, 0.0])
dx = [0.0, 0.0]
dy = [1.0]

Enzyme.autodiff(Enzyme.Forward, grad,
                Enzyme.BatchDuplicated(x, vx),
                Enzyme.BatchDuplicated(dx, hess),
                Const(y),
                Const(dy))</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">()</code></pre><p>Again we obtain the first-order gradient. If we did not want to compute the gradient again, we could instead have used <code>Enzyme.BatchDuplicatedNoNeed(dx, hess)</code></p><pre><code class="language-julia hljs">g[1] == dx[1]</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>We have now the first row/column of the Hessian</p><pre><code class="language-julia hljs">hess[1][1] == 2.0

hess[1][2] == 1.0</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><p>as well as the second row/column</p><pre><code class="language-julia hljs">hess[2][1] == 1.0

hess[2][2] == 0.0</code></pre><pre class="documenter-example-output"><code class="nohighlight hljs ansi">true</code></pre><hr/><p><em>This page was generated using <a href="https://github.com/fredrikekre/Literate.jl">Literate.jl</a>.</em></p></article><nav class="docs-footer"><a class="docs-footer-prevpage" href="../box/">« Box model</a><a class="docs-footer-nextpage" href="../custom_rule/">Custom rules »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 0.27.25 on <span class="colophon-date" title="Wednesday 14 February 2024 02:15">Wednesday 14 February 2024</span>. Using Julia version 1.10.0.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
