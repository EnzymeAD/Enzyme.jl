<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Home · Enzyme.jl</title><meta name="title" content="Home · Enzyme.jl"/><meta property="og:title" content="Home · Enzyme.jl"/><meta property="twitter:title" content="Home · Enzyme.jl"/><meta name="description" content="Documentation for Enzyme.jl."/><meta property="og:description" content="Documentation for Enzyme.jl."/><meta property="twitter:description" content="Documentation for Enzyme.jl."/><meta property="og:url" content="https://enzyme.mit.edu/julia/"/><meta property="twitter:url" content="https://enzyme.mit.edu/julia/"/><link rel="canonical" href="https://enzyme.mit.edu/julia/"/><script data-outdated-warner src="assets/warner.js"></script><link href="https://cdnjs.cloudflare.com/ajax/libs/lato-font/3.0.0/css/lato-font.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/juliamono/0.050/juliamono.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/fontawesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/solid.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.2/css/brands.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/KaTeX/0.16.8/katex.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.3.6/require.min.js" data-main="assets/documenter.js"></script><script src="search_index.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-mocha.css" data-theme-name="catppuccin-mocha"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-macchiato.css" data-theme-name="catppuccin-macchiato"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-frappe.css" data-theme-name="catppuccin-frappe"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/catppuccin-latte.css" data-theme-name="catppuccin-latte"/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-dark.css" data-theme-name="documenter-dark" data-theme-primary-dark/><link class="docs-theme-link" rel="stylesheet" type="text/css" href="assets/themes/documenter-light.css" data-theme-name="documenter-light" data-theme-primary/><script src="assets/themeswap.js"></script><script src="https://plausible.io/js/plausible.js" data-domain="enzyme.mit.edu" defer></script></head><body><div id="documenter"><nav class="docs-sidebar"><a class="docs-logo" href><img src="assets/logo.svg" alt="Enzyme.jl logo"/></a><div class="docs-package-name"><span class="docs-autofit"><a href>Enzyme.jl</a></span></div><button class="docs-search-query input is-rounded is-small is-clickable my-2 mx-auto py-1 px-2" id="documenter-search-query">Search docs (Ctrl + /)</button><ul class="docs-menu"><li class="is-active"><a class="tocitem" href>Home</a><ul class="internal"><li><a class="tocitem" href="#Getting-started"><span>Getting started</span></a></li><li><a class="tocitem" href="#Reverse-mode"><span>Reverse mode</span></a></li><li><a class="tocitem" href="#Forward-mode"><span>Forward mode</span></a></li><li><a class="tocitem" href="#Convenience-functions-(gradient,-jacobian,-hessian)"><span>Convenience functions (gradient, jacobian, hessian)</span></a></li><li><a class="tocitem" href="#Defining-rules"><span>Defining rules</span></a></li></ul></li><li><span class="tocitem">Examples</span><ul><li><a class="tocitem" href="generated/autodiff/">Basics</a></li><li><a class="tocitem" href="generated/box/">Box model</a></li><li><a class="tocitem" href="generated/custom_rule/">Custom rules</a></li></ul></li><li><span class="tocitem">Notebooks</span><ul><li><a class="tocitem" href="notebooks/ignore_derivatives/">Ignore derivatives</a></li></ul></li><li><a class="tocitem" href="faq/">FAQ</a></li><li><a class="tocitem" href="api/">API reference</a></li><li><span class="tocitem">Advanced</span><ul><li><a class="tocitem" href="dev_docs/">For developers</a></li><li><a class="tocitem" href="internal_api/">Internal API</a></li></ul></li></ul><div class="docs-version-selector field has-addons"><div class="control"><span class="docs-label button is-static is-size-7">Version</span></div><div class="docs-selector control is-expanded"><div class="select is-fullwidth is-size-7"><select id="documenter-version-selector"></select></div></div></div></nav><div class="docs-main"><header class="docs-navbar"><a class="docs-sidebar-button docs-navbar-link fa-solid fa-bars is-hidden-desktop" id="documenter-sidebar-button" href="#"></a><nav class="breadcrumb"><ul class="is-hidden-mobile"><li class="is-active"><a href>Home</a></li></ul><ul class="is-hidden-tablet"><li class="is-active"><a href>Home</a></li></ul></nav><div class="docs-right"><a class="docs-navbar-link" href="https://github.com/EnzymeAD/Enzyme.jl/blob/main/docs/src/index.md#" title="Edit source on GitHub"><span class="docs-icon fa-solid"></span></a><a class="docs-settings-button docs-navbar-link fa-solid fa-gear" id="documenter-settings-button" href="#" title="Settings"></a><a class="docs-article-toggle-button fa-solid fa-chevron-up" id="documenter-article-toggle-button" href="javascript:;" title="Collapse all docstrings"></a></div></header><article class="content" id="documenter-page"><h1 id="Enzyme"><a class="docs-heading-anchor" href="#Enzyme">Enzyme</a><a id="Enzyme-1"></a><a class="docs-heading-anchor-permalink" href="#Enzyme" title="Permalink"></a></h1><p>Documentation for <a href="https://github.com/EnzymeAD/Enzyme.jl">Enzyme.jl</a>, the Julia bindings for <a href="https://github.com/EnzymeAD/enzyme">Enzyme</a>.</p><p>Enzyme performs automatic differentiation (AD) of statically analyzable LLVM. It is highly-efficient and its ability to perform AD on optimized code allows Enzyme to meet or exceed the performance of state-of-the-art AD tools.</p><h2 id="Getting-started"><a class="docs-heading-anchor" href="#Getting-started">Getting started</a><a id="Getting-started-1"></a><a class="docs-heading-anchor-permalink" href="#Getting-started" title="Permalink"></a></h2><p>Enzyme.jl can be installed in the usual way Julia packages are installed:</p><pre><code class="nohighlight hljs">] add Enzyme</code></pre><p>The Enzyme binary dependencies will be installed automatically via Julia&#39;s binary artifact system.</p><p>The Enzyme.jl API revolves around the function <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a>. For some common operations, Enzyme additionally wraps <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a> in several convenience functions; e.g., <a href="api/#Enzyme.gradient-Union{Tuple{N}, Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{ty_0}, Tuple{F}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, F, ty_0, Vararg{Any, N}}} where {F, ty_0, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten, N}"><code>gradient</code></a> and <a href="api/#Enzyme.jacobian-Tuple{ForwardMode, Vararg{Any}}"><code>jacobian</code></a>.</p><p>The tutorial below covers the basic usage of these functions. For a complete overview of Enzyme&#39;s functionality, see the <a href="api/#API-reference">API reference</a> documentation. Also see <a href="faq/#Implementing-pullbacks">Implementing pullbacks</a> on how to implement back-propagation for functions with non-scalar results.</p><p>We will try a few things with the following functions:</p><pre><code class="language-julia-repl hljs">julia&gt; rosenbrock(x, y) = (1.0 - x)^2 + 100.0 * (y - x^2)^2
rosenbrock (generic function with 1 method)

julia&gt; rosenbrock_inp(x) = (1.0 - x[1])^2 + 100.0 * (x[2] - x[1]^2)^2
rosenbrock_inp (generic function with 1 method)</code></pre><h2 id="Reverse-mode"><a class="docs-heading-anchor" href="#Reverse-mode">Reverse mode</a><a id="Reverse-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Reverse-mode" title="Permalink"></a></h2><p>The return value of reverse mode <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a> is a tuple that contains as a first value the derivative value of the active inputs and optionally the primal return value.</p><pre><code class="language-julia-repl hljs">julia&gt; autodiff(Reverse, rosenbrock, Active, Active(1.0), Active(2.0))
((-400.0, 200.0),)

julia&gt; autodiff(ReverseWithPrimal, rosenbrock, Active, Active(1.0), Active(2.0))
((-400.0, 200.0), 100.0)</code></pre><pre><code class="language-julia-repl hljs">julia&gt; x = [1.0, 2.0]
2-element Vector{Float64}:
 1.0
 2.0

julia&gt; dx = [0.0, 0.0]
2-element Vector{Float64}:
 0.0
 0.0

julia&gt; autodiff(Reverse, rosenbrock_inp, Active, Duplicated(x, dx))
((nothing,),)

julia&gt; dx
2-element Vector{Float64}:
 -400.0
  200.0</code></pre><p>Both the inplace and &quot;normal&quot; variant return the gradient. The difference is that with <a href="api/#EnzymeCore.Active"><code>Active</code></a> the gradient is returned and with <a href="api/#EnzymeCore.Duplicated"><code>Duplicated</code></a> the gradient is accumulated in place.</p><h2 id="Forward-mode"><a class="docs-heading-anchor" href="#Forward-mode">Forward mode</a><a id="Forward-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Forward-mode" title="Permalink"></a></h2><p>The return value when using <code>ForwardWithPrimal</code> is a tuple containing as the first value the derivative return value and as the second value the original value.</p><p>The return value when using <code>Forward</code> is a single-element tuple containing the derivative.</p><p>In forward mode <code>Duplicated(x, 0.0)</code> is equivalent to <code>Const(x)</code>, except that we can perform more optimizations for <code>Const</code>.</p><pre><code class="language-julia-repl hljs">julia&gt; autodiff(ForwardWithPrimal, rosenbrock, Const(1.0), Duplicated(3.0, 1.0))
(400.0, 400.0)

julia&gt; autodiff(Forward, rosenbrock, Const(1.0), Duplicated(3.0, 1.0))
(400.0,)

julia&gt; autodiff(ForwardWithPrimal, rosenbrock, Duplicated(1.0, 1.0), Const(3.0))
(-800.0, 400.0)

julia&gt; autodiff(Forward, rosenbrock, Duplicated(1.0, 1.0), Const(3.0))
(-800.0,)</code></pre><p>Of note, when we seed both arguments at once the tangent return is the sum of both.</p><pre><code class="language-julia-repl hljs">julia&gt; autodiff(ForwardWithPrimal, rosenbrock, Duplicated(1.0, 1.0), Duplicated(3.0, 1.0))
(-400.0, 400.0)

julia&gt; autodiff(Forward, rosenbrock, Duplicated(1.0, 1.0), Duplicated(3.0, 1.0))
(-400.0,)</code></pre><p>We can also use forward mode with our inplace method.</p><pre><code class="language-julia-repl hljs">julia&gt; x = [1.0, 3.0]
2-element Vector{Float64}:
 1.0
 3.0

julia&gt; dx = [1.0, 1.0]
2-element Vector{Float64}:
 1.0
 1.0

julia&gt; autodiff(ForwardWithPrimal, rosenbrock_inp, Duplicated, Duplicated(x, dx))
(-400.0, 400.0)</code></pre><p>Note the seeding through <code>dx</code>.</p><h3 id="Vector-forward-mode"><a class="docs-heading-anchor" href="#Vector-forward-mode">Vector forward mode</a><a id="Vector-forward-mode-1"></a><a class="docs-heading-anchor-permalink" href="#Vector-forward-mode" title="Permalink"></a></h3><p>We can also use vector mode to calculate both derivatives at once.</p><pre><code class="language-julia-repl hljs">julia&gt; autodiff(ForwardWithPrimal, rosenbrock, BatchDuplicated(1.0, (1.0, 0.0)), BatchDuplicated(3.0, (0.0, 1.0)))
((var&quot;1&quot; = -800.0, var&quot;2&quot; = 400.0), 400.0)

julia&gt; x = [1.0, 3.0]
2-element Vector{Float64}:
 1.0
 3.0

julia&gt; dx_1 = [1.0, 0.0]; dx_2 = [0.0, 1.0];

julia&gt; autodiff(ForwardWithPrimal, rosenbrock_inp, BatchDuplicated(x, (dx_1, dx_2)))
((var&quot;1&quot; = -800.0, var&quot;2&quot; = 400.0), 400.0)</code></pre><h2 id="Convenience-functions-(gradient,-jacobian,-hessian)"><a class="docs-heading-anchor" href="#Convenience-functions-(gradient,-jacobian,-hessian)">Convenience functions (gradient, jacobian, hessian)</a><a id="Convenience-functions-(gradient,-jacobian,-hessian)-1"></a><a class="docs-heading-anchor-permalink" href="#Convenience-functions-(gradient,-jacobian,-hessian)" title="Permalink"></a></h2><h3 id="Gradient-Convenience-functions"><a class="docs-heading-anchor" href="#Gradient-Convenience-functions">Gradient Convenience functions</a><a id="Gradient-Convenience-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Gradient-Convenience-functions" title="Permalink"></a></h3><div class="admonition is-info" id="Note-b64d2f4a8c7157f4"><header class="admonition-header">Note<a class="admonition-anchor" href="#Note-b64d2f4a8c7157f4" title="Permalink"></a></header><div class="admonition-body"><p>While the convenience functions discussed below use <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a> internally, they are generally more limited in their functionality. Beyond that, these convenience functions may also come with performance penalties; especially if one makes a closure of a multi-argument function instead of calling the appropriate multi-argument <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a> function directly.</p></div></div><p>Key convenience functions for common derivative computations are <a href="api/#Enzyme.gradient-Union{Tuple{N}, Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{ty_0}, Tuple{F}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, F, ty_0, Vararg{Any, N}}} where {F, ty_0, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten, N}"><code>gradient</code></a> (and its inplace variant <a href="api/#Enzyme.gradient!-Union{Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{F}, Tuple{X}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, X, F, X}} where {X&lt;:Array, F, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}"><code>gradient!</code></a>). Like <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a>, the mode (forward or reverse) is determined by the first argument.</p><p>The functions <a href="api/#Enzyme.gradient-Union{Tuple{N}, Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{ty_0}, Tuple{F}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, F, ty_0, Vararg{Any, N}}} where {F, ty_0, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten, N}"><code>gradient</code></a> and <a href="api/#Enzyme.gradient!-Union{Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{F}, Tuple{X}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, X, F, X}} where {X&lt;:Array, F, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}"><code>gradient!</code></a> compute the gradient of function with vector input and scalar return.</p><p>Gradient functions take a mode as the first argument. If the mode is <code>Reverse</code> or <code>Forward</code>, the return type is a tuple of gradients of each argument.  If the mode is <code>ReverseWithPrimal</code> or <code>ForwardWithPrimal</code>, the return type is a named tuple containing both the derivatives and the original return result.</p><pre><code class="language-julia-repl hljs">julia&gt; gradient(Reverse, rosenbrock_inp, [1.0, 2.0])
([-400.0, 200.0],)

julia&gt; gradient(ReverseWithPrimal, rosenbrock_inp, [1.0, 2.0])
(derivs = ([-400.0, 200.0],), val = 100.0)

julia&gt; # inplace variant
       dx = [0.0, 0.0];
       gradient!(Reverse, dx, rosenbrock_inp, [1.0, 2.0])
([-400.0, 200.0],)

julia&gt; dx
2-element Vector{Float64}:
 -400.0
  200.0

julia&gt; gradient(Forward, rosenbrock_inp, [1.0, 2.0])
([-400.0, 200.0],)

julia&gt; gradient(ForwardWithPrimal, rosenbrock_inp, [1.0, 2.0])
(derivs = ([-400.0, 200.0],), val = 100.0)

julia&gt; # in forward mode, we can also optionally pass a chunk size
       # to specify the number of derivatives computed simulateneously
       # using vector forward mode
       gradient(Forward, rosenbrock_inp, [1.0, 2.0]; chunk=Val(1))
([-400.0, 200.0],)</code></pre><h3 id="Jacobian-Convenience-functions"><a class="docs-heading-anchor" href="#Jacobian-Convenience-functions">Jacobian Convenience functions</a><a id="Jacobian-Convenience-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Jacobian-Convenience-functions" title="Permalink"></a></h3><p>The function <a href="api/#Enzyme.jacobian-Tuple{ForwardMode, Vararg{Any}}"><code>jacobian</code></a> computes the Jacobian of a function vector input and vector return. Like <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a> and <a href="api/#Enzyme.gradient-Union{Tuple{N}, Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{ty_0}, Tuple{F}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, F, ty_0, Vararg{Any, N}}} where {F, ty_0, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten, N}"><code>gradient</code></a>, the mode (forward or reverse) is determined by the first argument.</p><p>Again like <a href="api/#Enzyme.gradient-Union{Tuple{N}, Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{ty_0}, Tuple{F}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, F, ty_0, Vararg{Any, N}}} where {F, ty_0, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten, N}"><code>gradient</code></a>, if the mode is <code>Reverse</code> or <code>Forward</code>, the return type is a tuple of jacobians of each argument.  If the mode is <code>ReverseWithPrimal</code> or <code>ForwardWithPrimal</code>, the return type is a named tuple containing both the derivatives and the original return result.</p><p>Both forward and reverse modes take an optional chunk size to compute several derivatives simultaneously using vector mode, and reverse mode optionally takes <code>n_outs</code> which describes the shape of the output value.</p><pre><code class="language-julia-repl hljs">julia&gt; foo(x) = [rosenbrock_inp(x), prod(x)];

julia&gt; jacobian(Reverse, foo, [1.0, 2.0]) 
([-400.0 200.0; 2.0 1.0],)

julia&gt; jacobian(ReverseWithPrimal, foo, [1.0, 2.0]) 
(derivs = ([-400.0 200.0; 2.0 1.0],), val = [100.0, 2.0])

julia&gt; jacobian(Reverse, foo, [1.0, 2.0]; chunk=Val(2)) 
([-400.0 200.0; 2.0 1.0],)

julia&gt; jacobian(Reverse, foo, [1.0, 2.0]; chunk=Val(2), n_outs=Val((2,)))
([-400.0 200.0; 2.0 1.0],)

julia&gt; jacobian(Forward, foo, [1.0, 2.0])
([-400.0 200.0; 2.0 1.0],)

julia&gt; jacobian(Forward, foo, [1.0, 2.0], chunk=Val(2))
([-400.0 200.0; 2.0 1.0],)</code></pre><h3 id="Hessian-Vector-Product-Convenience-functions"><a class="docs-heading-anchor" href="#Hessian-Vector-Product-Convenience-functions">Hessian Vector Product Convenience functions</a><a id="Hessian-Vector-Product-Convenience-functions-1"></a><a class="docs-heading-anchor-permalink" href="#Hessian-Vector-Product-Convenience-functions" title="Permalink"></a></h3><p>Enzyme provides convenience functions for second-order derivative computations, like <a href="api/#Enzyme.hvp-Union{Tuple{X}, Tuple{F}, Tuple{F, X, X}} where {F, X}"><code>hvp</code></a> to compute Hessian vector products. Mathematically, this computes <span>$H(x) v$</span>, where <span>$H$</span> is the hessian operator.</p><p>Unlike <a href="api/#EnzymeCore.autodiff-Union{Tuple{A}, Tuple{FA}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ErrIfFuncWritten}, Tuple{Nargs}, Tuple{RABI}, Tuple{ReturnPrimal}, Tuple{ForwardMode{ReturnPrimal, RABI, ErrIfFuncWritten, RuntimeActivity, StrongZero}, FA, Type{A}, Vararg{Annotation, Nargs}}} where {ReturnPrimal, RABI&lt;:EnzymeCore.ABI, Nargs, ErrIfFuncWritten, RuntimeActivity, StrongZero, FA&lt;:Annotation, A&lt;:Annotation}"><code>autodiff</code></a> and <a href="api/#Enzyme.gradient-Union{Tuple{N}, Tuple{ErrIfFuncWritten}, Tuple{Holomorphic}, Tuple{ABI}, Tuple{StrongZero}, Tuple{RuntimeActivity}, Tuple{ReturnPrimal}, Tuple{ty_0}, Tuple{F}, Tuple{ReverseMode{ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten}, F, ty_0, Vararg{Any, N}}} where {F, ty_0, ReturnPrimal, RuntimeActivity, StrongZero, ABI, Holomorphic, ErrIfFuncWritten, N}"><code>gradient</code></a>, a mode is not specified. Here, Enzyme will choose to perform forward over reverse mode (generally the fastest for this type of operation).</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = sin(x[1] * x[2]);

julia&gt; hvp(f, [2.0, 3.0], [5.0, 2.7])
2-element Vector{Float64}:
 19.69268826373025
 16.201003759768003</code></pre><p>Enzyme also provides an in-place variant which will store the hessian vector product in a pre-allocated array (this will, however, still allocate another array for storing an intermediate gradient).</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = sin(x[1] * x[2])
f (generic function with 1 method)

julia&gt; res = Vector{Float64}(undef, 2);

julia&gt; hvp!(res, f, [2.0, 3.0], [5.0, 2.7]);

julia&gt; res
2-element Vector{Float64}:
 19.69268826373025
 16.201003759768003</code></pre><p>Finally. Enzyme provides a second in-place variant which simultaneously computes both the hessian vector product, and the gradient. This function uses no additional allocation, and is much more efficient than separately computing the hvp and the gradient.</p><pre><code class="language-julia-repl hljs">julia&gt; f(x) = sin(x[1] * x[2]);

julia&gt; res = Vector{Float64}(undef, 2);

julia&gt; grad = Vector{Float64}(undef, 2);

julia&gt; hvp_and_gradient!(res, grad, f, [2.0, 3.0], [5.0, 2.7])

julia&gt; res
2-element Vector{Float64}:
 19.69268826373025
 16.201003759768003

julia&gt; grad
2-element Vector{Float64}:
 2.880510859951098
 1.920340573300732</code></pre><h2 id="Defining-rules"><a class="docs-heading-anchor" href="#Defining-rules">Defining rules</a><a id="Defining-rules-1"></a><a class="docs-heading-anchor-permalink" href="#Defining-rules" title="Permalink"></a></h2><p>While Enzyme will automatically generate derivative functions for you, there may be instances in which it is necessary or helpful to define custom derivative rules. Enzyme has three primary ways for defining derivative rules: inactive annotations, <a href="api/#EnzymeCore.EnzymeRules.@easy_rule-Tuple{Any, Any, Vararg{Any}}"><code>EnzymeRules.@easy_rule</code></a> macro definitions, general purpose derivative rules, and importing from <code>ChainRules</code>.</p><h3 id="Inactive-Annotations"><a class="docs-heading-anchor" href="#Inactive-Annotations">Inactive Annotations</a><a id="Inactive-Annotations-1"></a><a class="docs-heading-anchor-permalink" href="#Inactive-Annotations" title="Permalink"></a></h3><p>The simplest custom derivative is simply telling Enzyme that a given function does not need to be differentiated. For example, consider computing <code>det(Unitary Matrix)</code>. The determinant is always 1 so the derivative is always zero. Without this high level mathematical insight, the default rule Enzyme generates will add up a bunch of numbers that eventually come to zero. Instead of unnecessarily doing this work, we can just tell Enzyme that the derivative is always zero.</p><p>In autodiff-parlance we are telling Enzyme that the given result is <code>inactive</code> (aka makes no impact on the derivative). This can be done as follows:</p><pre><code class="language-julia hljs">
# Our existing function and types
struct UnitaryMatrix
    ...
end

det(::UnitaryMatrix) = ...

using Enzyme.EnzymeRules

EnzymeRules.inactive(::typeof(det), ::UnitaryMatrix) = true</code></pre><p>Specifically, we define a new overload of the method <a href="api/#EnzymeCore.EnzymeRules.inactive"><code>EnzymeRules.inactive</code></a> where the first argument is the type of the function being marked inactive, and the corresponding arguments match the arguments we want to overload the method for. This enables us, for example, to only mark the determinant of the <code>UnitaryMatrix</code> class here as inactive, and not the determinant of a general Matrix.</p><p>Enzyme also supports a second way to mark things inactive, where the marker is &quot;less strong&quot; and not guaranteed to apply if other optimizations might otherwise simplify the code first.</p><pre><code class="language-julia hljs">EnzymeRules.inactive_noinl(::typeof(det), ::UnitaryMatrix) = true</code></pre><h3 id="man-easy-rule"><a class="docs-heading-anchor" href="#man-easy-rule">Easy Rules</a><a id="man-easy-rule-1"></a><a class="docs-heading-anchor-permalink" href="#man-easy-rule" title="Permalink"></a></h3><p>The recommended way for writing rules for most use cases is through the <a href="api/#EnzymeCore.EnzymeRules.@easy_rule-Tuple{Any, Any, Vararg{Any}}"><code>EnzymeRules.@easy_rule</code></a> macro. This macro enables users to write derivatives for any functions which only read from their arguments (e.g. do not overwrite memory), and has numbers, matricies of numbers, or tuples thereof as arguments/result types. </p><p>When writing an <a href="api/#EnzymeCore.EnzymeRules.@easy_rule-Tuple{Any, Any, Vararg{Any}}"><code>EnzymeRules.@easy_rule</code></a> one first describes the function signature one wants the derivative rule to apply to. In each subsequent line, one should write a tuple, where each element of the tuple represents the derivative of the corresponding input argument. In that sense writing an <a href="api/#EnzymeCore.EnzymeRules.@easy_rule-Tuple{Any, Any, Vararg{Any}}"><code>EnzymeRules.@easy_rule</code></a> is equivalent to specifying the Jacobian. Inside of this tuple, one can call arbitrary Julia code.</p><p>One can also define certain arguments as not having a derivative via <code>@Constant</code>. </p><p>For more information see the <a href="api/#EnzymeCore.EnzymeRules.@easy_rule-Tuple{Any, Any, Vararg{Any}}"><code>EnzymeRules.@easy_rule</code></a> documentation.</p><pre><code class="language-julia hljs">using Enzyme

function f(x, y)
    return (x*x, cos(y) * x)
end

Enzyme.EnzymeRules.@easy_rule(f(x,y),
    # df1/dx, #df1/dy
    (2*x, @Constant),
    # df2/dx, #df2/dy
    (cos(y), x * sin(y))
)

function g(x, y)
    return f(x, y)[2]
end

Enzyme.gradient(Reverse, g, 2.0, 3.0)

# output
(-0.9899924966004454, 0.2822400161197344)</code></pre><p>Enzyme will automatically generate efficient derivatives for forward mode, reverse mode, batched forward and reverse mode, overwritten data, inactive inputs, and more from the given specification macro.</p><h3 id="General-Purpose-EnzymeRules"><a class="docs-heading-anchor" href="#General-Purpose-EnzymeRules">General Purpose EnzymeRules</a><a id="General-Purpose-EnzymeRules-1"></a><a class="docs-heading-anchor-permalink" href="#General-Purpose-EnzymeRules" title="Permalink"></a></h3><p>Finally Enzyme supports general-purpose EnzymeRules. For a given function, one can specify arbitrary behavior to occur when differentiting a given function. This is useful if you want to write efficient derivatives for mutating code, are handling funky behavior like GPU/distributed runtime calls, and more.</p><p>Like before, Enzyme takes a specification of the function the rule applies to, and passes various configuration data for full user-level customization.</p><pre><code class="language-julia hljs">using Enzyme

function mysin(x)
    return sin(x)
end

function Enzyme.EnzymeRules.forward(config, ::Const{typeof(mysin)}, ::Type, x)
    # If we don&#39;t need the original result, let&#39;s avoid computing it (and print)
    if !needs_primal(config)
        println(&quot;Avoiding computing sin!&quot;)
        return cos(x.val) * x.dval
    else
        println(&quot;Still computing sin&quot;)
        return Duplicated(sin(x.val), cos(x.val) * x.dval)
    end
end

function mysquare(x)
    y = mysin(x)
    return y*y
end

# Prints &quot;Avoiding computing sin!&quot;
Enzyme.gradient(Forward, mysin, 2.0);

# Prints &quot;Still computing sin =/&quot; as d/dx sin(x)^2 = 2 * sin(x) * sin&#39;(x)
# so the original result is still needed
Enzyme.gradient(Forward, mysquare, 2.0);

# output
Avoiding computing sin!
Still computing sin
(-0.7568024953079283,)</code></pre><p>For more information, see <a href="generated/custom_rule/#custom_rules">the custom rule docs</a>, <a href="api/#EnzymeCore.EnzymeRules.forward"><code>EnzymeRules.forward</code></a>,  <a href="api/#EnzymeCore.EnzymeRules.augmented_primal"><code>EnzymeRules.augmented_primal</code></a>, and <a href="api/#EnzymeCore.EnzymeRules.reverse"><code>EnzymeRules.reverse</code></a>.</p><h3 id="Importing-ChainRules"><a class="docs-heading-anchor" href="#Importing-ChainRules">Importing ChainRules</a><a id="Importing-ChainRules-1"></a><a class="docs-heading-anchor-permalink" href="#Importing-ChainRules" title="Permalink"></a></h3><p>Enzyme can also import rules from the <code>ChainRules</code> ecosystem. This is often helpful when first getting started, though it will generally be much more efficient to write either an <a href="api/#EnzymeCore.EnzymeRules.@easy_rule-Tuple{Any, Any, Vararg{Any}}"><code>EnzymeRules.@easy_rule</code></a> or general custom rule.</p><p>Enzyme can import the forward rule, reverse rule, or both.</p><pre><code class="language-julia hljs">using Enzyme, ChainRulesCore

f(x) = sin(x)
ChainRulesCore.@scalar_rule f(x)  (cos(x),)

# Import the reverse rule for float32
Enzyme.@import_rrule typeof(f) Float32

# Import the forward rule for float32
Enzyme.@import_frule typeof(f) Float32

# output</code></pre><p>See the docs on <a href="api/#Enzyme.@import_frule-Tuple"><code>Enzyme.@import_frule</code></a> and <a href="api/#Enzyme.@import_rrule-Tuple"><code>Enzyme.@import_rrule</code></a> for more information.</p></article><nav class="docs-footer"><a class="docs-footer-nextpage" href="generated/autodiff/">Basics »</a><div class="flexbox-break"></div><p class="footer-message">Powered by <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> and the <a href="https://julialang.org/">Julia Programming Language</a>.</p></nav></div><div class="modal" id="documenter-settings"><div class="modal-background"></div><div class="modal-card"><header class="modal-card-head"><p class="modal-card-title">Settings</p><button class="delete"></button></header><section class="modal-card-body"><p><label class="label">Theme</label><div class="select"><select id="documenter-themepicker"><option value="auto">Automatic (OS)</option><option value="documenter-light">documenter-light</option><option value="documenter-dark">documenter-dark</option><option value="catppuccin-latte">catppuccin-latte</option><option value="catppuccin-frappe">catppuccin-frappe</option><option value="catppuccin-macchiato">catppuccin-macchiato</option><option value="catppuccin-mocha">catppuccin-mocha</option></select></div></p><hr/><p>This document was generated with <a href="https://github.com/JuliaDocs/Documenter.jl">Documenter.jl</a> version 1.15.0 on <span class="colophon-date" title="Tuesday 28 October 2025 13:41">Tuesday 28 October 2025</span>. Using Julia version 1.11.7.</p></section><footer class="modal-card-foot"></footer></div></div></div></body></html>
