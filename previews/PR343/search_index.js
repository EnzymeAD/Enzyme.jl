var documenterSearchIndex = {"docs":
[{"location":"api/#API","page":"API","title":"API","text":"","category":"section"},{"location":"api/#Types-and-constants","page":"API","title":"Types and constants","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [Enzyme]\nOrder = [:type, :constant]","category":"page"},{"location":"api/#Functions-and-macros","page":"API","title":"Functions and macros","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [Enzyme]\nOrder = [:macro, :function]","category":"page"},{"location":"api/#Documentation","page":"API","title":"Documentation","text":"","category":"section"},{"location":"api/","page":"API","title":"API","text":"Modules = [Enzyme]\nOrder = [:module, :type, :constant, :macro, :function]","category":"page"},{"location":"api/#Enzyme.Active","page":"API","title":"Enzyme.Active","text":"Active(x)\n\nMark a function argument x of autodiff as active, Enzyme will auto-differentiate in respect Active arguments.\n\nnote: Note\nEnzyme gradients with respect to integer values are zero. Active will automatically convert plain integers to floating point values, but cannot do so for integer values in tuples and structs.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.Annotation","page":"API","title":"Enzyme.Annotation","text":"abstract type Annotation{T}\n\nAbstract type for autodiff function argument wrappers like Const, Active and Duplicated.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.BatchDuplicated","page":"API","title":"Enzyme.BatchDuplicated","text":"BatchDuplicated(x, ∂f_∂xs)\n\nLike Duplicated, except contains several shadows to compute derivatives for all at once. Argument ∂f_∂xs should be a tuple of the several values of type x.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.BatchDuplicatedNoNeed","page":"API","title":"Enzyme.BatchDuplicatedNoNeed","text":"BatchDuplicatedNoNeed(x, ∂f_∂xs)\n\nLike DuplicatedNoNeed, except contains several shadows to compute derivatives for all at once. Argument ∂f_∂xs should be a tuple of the several values of type x.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.Const","page":"API","title":"Enzyme.Const","text":"Const(x)\n\nMark a function argument x of autodiff as constant, Enzyme will not auto-differentiate in respect Const arguments.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.Duplicated","page":"API","title":"Enzyme.Duplicated","text":"Duplicated(x, ∂f_∂x)\n\nMark a function argument x of autodiff as duplicated, Enzyme will auto-differentiate in respect to such arguments, with dx acting as an accumulator for gradients (so partial f  partial x will be added to) ∂f_∂x.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.DuplicatedNoNeed","page":"API","title":"Enzyme.DuplicatedNoNeed","text":"DuplicatedNoNeed(x, ∂f_∂x)\n\nLike Duplicated, except also specifies that Enzyme may avoid computing the original result and only compute the derivative values.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.ForwardMode","page":"API","title":"Enzyme.ForwardMode","text":"struct Forward <: Mode\n\nForward mode differentiation\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.Mode","page":"API","title":"Enzyme.Mode","text":"abstract type Mode\n\nAbstract type for what differentiation mode will be used.\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.ReverseMode","page":"API","title":"Enzyme.ReverseMode","text":"struct Reverse <: Mode\n\nReverse mode differentiation\n\n\n\n\n\n","category":"type"},{"location":"api/#Enzyme.autodiff-Union{Tuple{A}, Tuple{F}, Tuple{Enzyme.ForwardMode, F, Type{A}, Vararg{Any}}} where {F, A<:Enzyme.Annotation}","page":"API","title":"Enzyme.autodiff","text":"autodiff(::ForwardMode, f, Activity, args...)\n\nAuto-differentiate function f at arguments args using forward mode.\n\nargs may be numbers, arrays, structs of numbers, structs of arrays and so on. Enzyme will only differentiate in respect to arguments that are wrapped in a Duplicated or similar argument. Non-annotated arguments will automatically be treated as Const. Unlike reverse mode in autodiff, Active arguments are not allowed here, since all \n\nActivity is the Activity of the return value, it may be:\n\nConst if the return is not to be differentiated with respect to\nDuplicated, if the return is being differentiated with respect to and both the original value and the derivative return are desired\nDuplicatedNoNeed, if the return is being differentiated with respect to and only the derivative return is desired.\n\nExample returning both original return and derivative:\n\na = 4.2\nb = [2.2, 3.3]; ∂f_∂b = zero(b)\nc = 55; d = 9\n\nf(x) = x*x\nres, ∂f_∂x = autodiff(Forward, f, Duplicated, Duplicated(3.14, 1.0))\n\n# output\n\n(9.8596, 6.28)\n\nExample returning just the derivative:\n\na = 4.2\nb = [2.2, 3.3]; ∂f_∂b = zero(b)\nc = 55; d = 9\n\nf(x) = x*x\n∂f_∂x = autodiff(Forward, f, DuplicatedNoNeed, Duplicated(3.14, 1.0))\n\n# output\n\n(6.28,)\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.autodiff-Union{Tuple{A}, Tuple{F}, Tuple{Enzyme.ReverseMode, F, Type{A}, Vararg{Any}}} where {F, A<:Enzyme.Annotation}","page":"API","title":"Enzyme.autodiff","text":"autodiff(::ReverseMode, f, Activity, args...)\n\nAuto-differentiate function f at arguments args using reverse mode.\n\nLimitations:\n\nf may only return a Real (of a built-in/primitive type) or nothing, not an array, struct, BigFloat, etc. To handle vector-valued return types, use a mutating f! that returns nothing and stores it's return value in one of the arguments, which must be wrapped in a Duplicated.\n\nargs may be numbers, arrays, structs of numbers, structs of arrays and so on. Enzyme will only differentiate in respect to arguments that are wrapped in an Active (for immutable arguments like primitive types and structs thereof) or Duplicated (for mutable arguments like arrays, Refs and structs thereof). Non-annotated arguments will automatically be treated as Const.\n\nActivity is the Activity of the return value, it may be Const or Active.\n\nExample:\n\na = 4.2\nb = [2.2, 3.3]; ∂f_∂b = zero(b)\nc = 55; d = 9\n\nf(a, b, c, d) = a * √(b[1]^2 + b[2]^2) + c^2 * d^2\n∂f_∂a, ∂f_∂d = autodiff(Reverse, f, Active, Active(a), Duplicated(b, ∂f_∂b), c, Active(d))\n\n# output\n\n(3.966106403010388, 54450.0)\n\nhere, autodiff returns a tuple (partial fpartial a partial fpartial d), while partial fpartial b will be added to ∂f_∂b (but not returned). c will be treated as Const(c).\n\nnote: Note\nEnzyme gradients with respect to integer values are zero. Active will automatically convert plain integers to floating point values, but cannot do so for integer values in tuples and structs.\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.autodiff-Union{Tuple{F}, Tuple{Enzyme.Mode, F, Vararg{Any}}} where F","page":"API","title":"Enzyme.autodiff","text":"autodiff(mode::Mode, f, args...)\nautodiff(f, mode::Mode, args...)\n\nLike autodiff but will try to guess the activity of the return value.\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.autodiff_deferred-Union{Tuple{A}, Tuple{F}, Tuple{F, Type{A}, Vararg{Any}}} where {F, A<:Enzyme.Annotation}","page":"API","title":"Enzyme.autodiff_deferred","text":"autodiff_deferred(f, Activity, args...)\n\nSame as autodiff but uses deferred compilation to support usage in GPU code, as well as high-order differentiation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.autodiff_deferred-Union{Tuple{F}, Tuple{F, Vararg{Any}}} where F","page":"API","title":"Enzyme.autodiff_deferred","text":"autodiff_deferred(f, args...)\n\nLike autodiff_deferred but will try to guess the activity of the return value.\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.fwddiff_deferred-Union{Tuple{A}, Tuple{F}, Tuple{F, Type{A}, Vararg{Any}}} where {F, A<:Enzyme.Annotation}","page":"API","title":"Enzyme.fwddiff_deferred","text":"fwddiff_deferred(f, Activity, args...)\n\nSame as autodiff(::ForwardMode, ...) but uses deferred compilation to support usage in GPU code, as well as high-order differentiation.\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.fwddiff_deferred-Union{Tuple{F}, Tuple{F, Vararg{Any}}} where F","page":"API","title":"Enzyme.fwddiff_deferred","text":"fwddiff_deferred(f, args...)\n\nLike fwddiff_deferred but will try to guess the activity of the return value.\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.gradient!-Tuple{Enzyme.ReverseMode, Any, Any, Any}","page":"API","title":"Enzyme.gradient!","text":"gradient!(::ReverseMode, dx, f, x)\n\nCompute the gradient of an array-input function f using reverse mode, storing the derivative result in an existing array dx.\n\nExample:\n\nf(x) = x[1]*x[2]\n\ndx = [0.0, 0.0]\ngradient!(Reverse, dx, f, [2.0, 3.0])\n\n# output\n\n2-element Vector{Float64}:\n 3.0\n 2.0\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.gradient-Tuple{Enzyme.ForwardMode, Any, Any}","page":"API","title":"Enzyme.gradient","text":"gradient(::ForwardMode, f, x; shadow=onehot(x))\n\nCompute the gradient of an array-input function f using forward mode. The optional keyword argument shadow is a vector of one-hot vectors of type x which are used to forward-propagate into the return. For performance reasons, this should be computed once, outside the call to gradient, rather than within this call.\n\nExample:\n\nf(x) = x[1]*x[2]\n\ngrad = gradient(Forward, f, [2.0, 3.0])\n\n# output\n\n(3.0, 2.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.gradient-Tuple{Enzyme.ReverseMode, Any, Any}","page":"API","title":"Enzyme.gradient","text":"gradient(::ReverseMode, f, x)\n\nCompute the gradient of an array-input function f using reverse mode. This will allocate and return new array with the gradient result.\n\nExample:\n\nf(x) = x[1]*x[2]\n\ngrad = gradient(Reverse, f, [2.0, 3.0])\n\n# output\n\n2-element Vector{Float64}:\n 3.0\n 2.0\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.gradient-Union{Tuple{chunk}, Tuple{Enzyme.ForwardMode, Any, Any, Val{chunk}}} where chunk","page":"API","title":"Enzyme.gradient","text":"gradient(::ForwardMode, f, x, ::Val{chunk}; shadow=onehot(x))\n\nCompute the gradient of an array-input function f using vector forward mode. Like gradient, except it uses a chunk size of chunk to compute chunk derivatives in a single call.\n\nExample:\n\nf(x) = x[1]*x[2]\n\ngrad = gradient(Forward, f, [2.0, 3.0], Val(2))\n\n# output\n\n(3.0, 2.0)\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.jacobian-Tuple{Enzyme.ForwardMode, Vararg{Any}}","page":"API","title":"Enzyme.jacobian","text":"jacobian(::ForwardMode, f, x; shadow=onehot(x))\njacobian(::ForwardMode, f, x, ::Val{chunk}; shadow=onehot(x))\n\nCompute the jacobian of an array-input function f using (potentially vector) forward mode. This is a simple rename of the gradient function, and all relevant arguments apply here.\n\nExample:\n\nf(x) = [x[1]*x[2], x[2]]\n\ngrad = jacobian(Forward, f, [2.0, 3.0])\n\n# output\n\n2×2 Matrix{Float64}:\n 3.0  2.0\n 0.0  1.0\n\n\n\n\n\n","category":"method"},{"location":"api/#Enzyme.jacobian-Union{Tuple{n_out_val}, Tuple{chunk}, Tuple{Enzyme.ReverseMode, Any, Any, Val{n_out_val}, Val{chunk}}} where {chunk, n_out_val}","page":"API","title":"Enzyme.jacobian","text":"jacobian(::ReverseMode, f, x, ::Val{num_outs}, ::Val{chunk})\n\nCompute the jacobian of an array-input function f using (potentially vector) reverse mode. The chunk argument denotes the chunk size to use and num_outs denotes the number of outputs f will return in an array.\n\nExample:\n\nf(x) = [x[1]*x[2], x[2]]\n\ngrad = jacobian(Reverse, f, [2.0, 3.0], Val(2))\n\n# output\n\n2×2 Matrix{Float64}:\n 3.0  2.0\n 0.0  1.0\n\n\n\n\n\n","category":"method"},{"location":"pullbacks/#Implementing-pullbacks","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"","category":"section"},{"location":"pullbacks/","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"Enzyme's autodiff function can only handle functions with scalar output. To implement pullbacks (back-propagation of gradients/tangents) for array-valued functions, use a mutating function that returns nothing and stores it's result in one of the arguments, which must be passed wrapped in a Duplicated.","category":"page"},{"location":"pullbacks/#Example","page":"Implementing pullbacks","title":"Example","text":"","category":"section"},{"location":"pullbacks/","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"Given a function mymul! that performs the equivalent of R = A * B for matrices A and B, and given a gradient (tangent) ∂z_∂R, we can compute ∂z_∂A and ∂z_∂B like this:","category":"page"},{"location":"pullbacks/","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"using Enzyme\n\nfunction mymul!(R, A, B)\n    @assert axes(A,2) == axes(B,1)\n    @inbounds @simd for i in eachindex(R)\n        R[i] = 0\n    end\n    @inbounds for j in axes(B, 2), i in axes(A, 1)\n        @inbounds @simd for k in axes(A,2)\n            R[i,j] += A[i,k] * B[k,j]\n        end\n    end\n    nothing\nend\n\n\nA = rand(5, 3)\nB = rand(3, 7)\n\nR = zeros(size(A,1), size(B,2))\n∂z_∂R = rand(size(R)...)  # Some gradient/tangent passed to us\n\n∂z_∂A = zero(A)\n∂z_∂B = zero(B)\n\nEnzyme.autodiff(mymul!, Const, Duplicated(R, ∂z_∂R), Duplicated(A, ∂z_∂A), Duplicated(B, ∂z_∂B))","category":"page"},{"location":"pullbacks/","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"Now we have:","category":"page"},{"location":"pullbacks/","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"R ≈ A * B            &&\n∂z_∂A ≈ ∂z_∂R * B'   &&  # equivalent to Zygote.pullback(*, A, B)[2](∂z_∂R)[1]\n∂z_∂B ≈ A' * ∂z_∂R       # equivalent to Zygote.pullback(*, A, B)[2](∂z_∂R)[2]","category":"page"},{"location":"pullbacks/","page":"Implementing pullbacks","title":"Implementing pullbacks","text":"Note that the result of the backpropagation is added to ∂z_∂A and ∂z_∂B, they act as accumulators for gradient information.","category":"page"},{"location":"dev_docs/#Enzyme-developer-documentation","page":"For developers","title":"Enzyme developer documentation","text":"","category":"section"},{"location":"dev_docs/#Development-of-Enzyme-and-Enzyme.jl-together","page":"For developers","title":"Development of Enzyme and Enzyme.jl together","text":"","category":"section"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"Normally Enzyme.jl downloads and install Enzyme for the user automatically since Enzyme needs to be built against Julia bundeled LLVM. In case that you are making updates to Enzyme and want to test them against Enzyme.jl the instructions below should help you get started.","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"Start Julia in your development copy of Enzyme.jl","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"~/s/Enzyme (master)> julia --project=.","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"Then create a development copy of Enzyme_jll and activate it within.","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"julia> using Enzyme_jll\njulia> Enzyme_jll.dev_jll()\n[ Info: Enzyme_jll dev'ed out to ${JULIA_PKG_DEVDIR}/Enzyme_jll with pre-populated override directory\n(Enzyme) pkg> dev Enzyme_jll\nPath `${JULIA_PKG_DEVDIR}/Enzyme_jll` exists and looks like the correct package. Using existing path.","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"After restarting Julia:","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"julia> Enzyme_jll.dev_jll()\njulia> Enzyme_jll.libEnzyme_path\n\"${JULIA_PKG_DEVDIR}/Enzyme_jll/override/lib/LLVMEnzyme-9.so\"","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"On your machine ${JULIA_PKG_DEVDIR} most likely corresponds to ~/.julia/dev. Now we can inspect \"${JULIA_PKG_DEVDIR}/Enzyme_jll/override/lib and see that there is a copy of LLVMEnzyme-9.so, which we can replace with a symbolic link or a copy of a version of Enzyme.","category":"page"},{"location":"dev_docs/#Building-Enzyme-against-Julia's-LLVM.","page":"For developers","title":"Building Enzyme against Julia's LLVM.","text":"","category":"section"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"Depending on how you installed Julia the LLVM Julia is using will be different.","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"Download from julialang.org (Recommended)\nManual build on your machine\nUses a pre-built Julia from your system vendor (Not recommended)","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"To check what LLVM Julia is using use:","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"julia> Base.libllvm_version_string\n\"9.0.1jl\"","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"If the LLVM version ends in a jl you a likely using the private LLVM.","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"In your source checkout of Enzyme:","category":"page"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"mkdir build-jl\ncd build-jl","category":"page"},{"location":"dev_docs/#Prebuilt-binary-from-julialang.org","page":"For developers","title":"Prebuilt binary from julialang.org","text":"","category":"section"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"LLVM_MAJOR_VER=`julia -e \"print(Base.libllvm_version.major)\"`\njulia -e \"using Pkg; pkg\\\"add LLVM_full_jll@${LLVM_MAJOR_VER}\\\"\"\nLLVM_DIR=`julia -e \"using LLVM_full_jll; print(LLVM_full_jll.artifact_dir)\"`\necho \"LLVM_DIR=$LLVM_DIR\"\ncmake ../enzyme/ -G Ninja -DENZYME_EXTERNAL_SHARED_LIB=ON -DLLVM_DIR=${LLVM_DIR} -DLLVM_EXTERNAL_LIT=${LLVM_DIR}/tools/lit/lit.py","category":"page"},{"location":"dev_docs/#Manual-build-of-Julia","page":"For developers","title":"Manual build of Julia","text":"","category":"section"},{"location":"dev_docs/","page":"For developers","title":"For developers","text":"cmake ../enzyme/ -G Ninja -DENZYME_EXTERNAL_SHARED_LIB=ON -DLLVM_DIR=${PATH_TO_BUILDDIR_OF_JULIA}/usr/lib/cmake/llvm/","category":"page"},{"location":"internal_api/#Internal-API","page":"Internal API","title":"Internal API","text":"","category":"section"},{"location":"internal_api/","page":"Internal API","title":"Internal API","text":"note: Note\nThis is the documentation of Enzymes's internal API. The internal API is not subject to semantic versioning and may change at any time and without deprecation.","category":"page"},{"location":"internal_api/","page":"Internal API","title":"Internal API","text":"Modules = [Enzyme.Compiler]\nOrder = [:module, :type, :constant, :macro, :function]","category":"page"},{"location":"internal_api/#Enzyme.Compiler.fspec-Tuple{Any, Any}","page":"Internal API","title":"Enzyme.Compiler.fspec","text":"Create the FunctionSpec pair, and lookup the primal return type.\n\n\n\n\n\n","category":"method"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"EditURL = \"https://github.com/EnzymeAD/Enzyme.jl/blob/main/examples/box.jl\"","category":"page"},{"location":"generated/box/#Enzyme-for-adjoint-tutorial:-Stommel-three-box-ocean-model","page":"Box model","title":"Enzyme for adjoint tutorial: Stommel three-box ocean model","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"The goal of this tutorial is to teach about a specific usage of Enzyme's automatic differentiation capabilities, and will be centered around the Stommel ocean model. This is a nice example to see how powerful Enzyme is, and the ability of it to take a derivative of a complicated function (namely one that has many parts and parameters). This tutorial will focus first on the computations and getting Enzyme running, for those interested a mathematical explanation of the model and what an adjoint variable is will be provided at the end.","category":"page"},{"location":"generated/box/#Brief-model-overview","page":"Box model","title":"Brief model overview","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"The Stommel box model can be viewed as a watered down full ocean model. In our example, we have three boxes (Box One, Box Two, and Box Three) and we model the transport of fluid between them. The full equations of our system are given by:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"beginaligned\n   U = u_0 left rho_2 - left rho_1 + (1 - delta) rho_3 right right \n   rho_i = -alpha T_i + beta S_i     i = 1 2 3\nendaligned","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"for the transport U and densities rho, and then the time derivatives","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"beginaligned\n   dotT_1 = U(T_3 - T_1)V_1 + gamma (T_1^* - T_1 )  dotS_1 = U(S_3 - S_1)V_1 + FW_1V_1 \n   dotT_2 = U(T_1 - T_2)V_2 + gamma (T_2^* - T_2 )  dotS_2 = U(S_1 - S_2)V_2 + FW_2V_2 \n   dotT_3 = U(T_2 - T_3)V_3  dotS_3 = U(S_2 - S_3)V_3\nendaligned","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"for positive transport, U  0, and","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"beginaligned\n   dotT_1 = U(T_2 - T_1)V_1 + gamma (T_1^* - T_1)  dotS_1 = U(S_2 - S_1)V_1 + FW_1V_1 \n   dotT_2 = U(T_3 - T_2)V_2 + gamma (T_2^* - T_2 )  dotS_2 = U(S_3 - S_2)V_2 + FW_2V_2 \n   dotT_3 = U(T_1 - T_3)V_3  dotS_3 = U(S_1 - S_3)V_3\nendaligned","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"for U leq 0. The only force driving our system is a density gradient generated via temperature and salinity differences between the boxes. This makes it a really easy model to play around with! With this in mind, the model is run forward with the steps:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Compute densities\nCompute transport\nCompute time derivatives of the box temperatures and salinities\nUpdate the state vector","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"We'll start by going through the model setup step by step, then providing a few test cases with Enzyme.","category":"page"},{"location":"generated/box/#Model-setup","page":"Box model","title":"Model setup","text":"","category":"section"},{"location":"generated/box/#Model-dependencies","page":"Box model","title":"Model dependencies","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Let's first add the necessary packages to run everything","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"using Enzyme","category":"page"},{"location":"generated/box/#Initialize-constants","page":"Box model","title":"Initialize constants","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"The system equations have quite a few constants that appear, here we initialize them for later use","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"const blength = [5000.0e5; 1000.0e5; 5000.0e5]   ## north-south size of boxes, centimeters\n\nconst bdepth = [1.0e5; 5.0e5; 4.0e5]   ## depth of boxes, centimeters\n\nconst delta = bdepth[1]/(bdepth[1] + bdepth[3])  ## constant ratio of two depths\n\nconst bwidth = 4000.0*1e5  ## box width, centimeters\n\n# box areas\nconst barea = [blength[1]*bwidth;\n         blength[2]*bwidth;\n         blength[3]*bwidth]\n\n# box volumes\nconst bvol = [barea[1]*bdepth[1];\n        barea[2]*bdepth[2];\n        barea[3]*bdepth[3]]\n\n# parameters that are used to ensure units are in CGS (cent-gram-sec)\n\nconst hundred = 100.0\nconst thousand = 1000.0\nconst day = 3600.0*24.0\nconst year = day*365.0\nconst Sv = 1e12     ## one Sverdrup (a unit of ocean transport), 1e6 meters^3/second\n\n# parameters that appear in box model equations\nconst u0 = 16.0*Sv/0.0004\nconst alpha = 1668e-7\nconst beta = 0.7811e-3\n\nconst gamma = 1/(300*day)\n\n# robert filter coefficient for the smoother part of the timestep\nconst robert_filter_coeff = 0.25\n\n# freshwater forcing\nconst FW = [(hundred/year) * 35.0 * barea[1]; -(hundred/year) * 35.0 * barea[1]]\n\n# restoring atmospheric temperatures\nconst Tstar = [22.0; 0.0]\nconst Sstar = [36.0; 34.0];\nnothing #hide","category":"page"},{"location":"generated/box/#Define-model-functions","page":"Box model","title":"Define model functions","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Here we define functions that will calculate quantities used in the forward steps.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"# function to compute transport\n#       Input: rho - the density vector\n#       Output: U - transport value\n\nfunction U_func(dens)\n\n    U = u0*(dens[2] - (delta * dens[1] + (1 - delta)*dens[3]))\n    return U\n\nend\n\n# function to compute density\n#       Input: state = [T1; T2; T3; S1; S2; S3]\n#       Output: rho\n\nfunction rho_func(state)\n\n    rho = zeros(3)\n\n    rho[1] = -alpha * state[1] + beta * state[4]\n    rho[2] = -alpha * state[2] + beta * state[5]\n    rho[3] = -alpha * state[3] + beta * state[6]\n\n    return rho\n\nend\n\n# lastly our timestep function\n#       Input: fld_now = [T1(t), T2(t), ..., S3(t)]\n#           fld_old = [T1(t-dt), ..., S3(t-dt)]\n#           u = transport(t)\n#           dt = time step\n#       Output: fld_new = [T1(t+dt), ..., S3(t+dt)]\n\nfunction timestep_func(fld_now, fld_old, u, dt)\n\n    temp = zeros(6)\n    fld_new = zeros(6)\n\n    # first computing the time derivatives of the various temperatures and salinities\n    if u > 0\n\n        temp[1] = u * (fld_now[3] - fld_now[1]) / bvol[1] + gamma * (Tstar[1] - fld_now[1])\n        temp[2] = u * (fld_now[1] - fld_now[2]) / bvol[2] + gamma * (Tstar[2] - fld_now[2])\n        temp[3] = u * (fld_now[2] - fld_now[3]) / bvol[3]\n\n        temp[4] = u * (fld_now[6] - fld_now[4]) / bvol[1] + FW[1] / bvol[1]\n        temp[5] = u * (fld_now[4] - fld_now[5]) / bvol[2] + FW[2] / bvol[2]\n        temp[6] = u * (fld_now[5] - fld_now[6]) / bvol[3]\n\n    elseif u <= 0\n\n        temp[1] = u * (fld_now[2] - fld_now[1]) / bvol[1] + gamma * (Tstar[1] - fld_now[1])\n        temp[2] = u * (fld_now[3] - fld_now[2]) / bvol[2] + gamma * (Tstar[2] - fld_now[2])\n        temp[3] = u * (fld_now[1] - fld_now[3]) / bvol[3]\n\n        temp[4] = u * (fld_now[5] - fld_now[4]) / bvol[1] + FW[1] / bvol[1]\n        temp[5] = u * (fld_now[6] - fld_now[5]) / bvol[2] + FW[2] / bvol[2]\n        temp[6] = u * (fld_now[4] - fld_now[6]) / bvol[3]\n\n    end\n\n    # update fldnew using a version of Euler's method\n\n    for j = 1:6\n        fld_new[j] = fld_old[j] + 2.0 * dt * temp[j]\n    end\n\n    return fld_new\nend","category":"page"},{"location":"generated/box/#Define-forward-functions","page":"Box model","title":"Define forward functions","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Finally, we create two functions, bthe first of which computes and stores all the states of the system, and the second which has been written specifically to be passed to Enzyme.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Let's start with the standard forward function. This is just going to be used to store the states at every timestep:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"function forward_func(fld_old, fld_now, dt, M)\n\n    state_now = copy(fld_now)\n    state_old = copy(fld_old)\n    state_new = zeros(6)\n\n    states_unsmooth = [state_old];\n    states_smooth = [state_old]\n\n    for t = 1:M\n        rho_now = rho_func(state_now)\n        u_now = U_func(rho_now)\n        state_new = timestep_func(state_now, state_old, u_now, dt)\n\n        # Robert filter smoother (needed for stability)\n        for j = 1:6\n            state_now[j] = state_now[j] + robert_filter_coeff * (state_new[j] - 2.0 * state_now[j] + state_old[j])\n        end\n\n        push!(states_smooth, copy(state_now))\n        push!(states_unsmooth, copy(state_new))\n\n        # cycle the \"now, new, old\" states\n\n        state_old = state_now\n        state_now = state_new\n    end\n\n    return states_smooth, states_unsmooth\nend","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Next, we have the Enzyme-designed forward function. This is what we'll actually be passing to Enzyme to differentiate:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"function forward_func_4_AD(in_now, in_old, out_old, out_now)\n\n    rho_now = rho_func(in_now)                             ## compute density\n    u_now = U_func(rho_now)                                ## compute transport\n    in_new = timestep_func(in_now, in_old, u_now, 10*day)  ## compute new state values\n\n    # Robert filter smoother\n    in_now[1] = in_now[1] + robert_filter_coeff * (in_new[1] - 2.0 * in_now[1] + in_old[1])\n    in_now[2] = in_now[2] + robert_filter_coeff * (in_new[2] - 2.0 * in_now[2] + in_old[2])\n    in_now[3] = in_now[3] + robert_filter_coeff * (in_new[3] - 2.0 * in_now[3] + in_old[3])\n    in_now[4] = in_now[4] + robert_filter_coeff * (in_new[4] - 2.0 * in_now[4] + in_old[4])\n    in_now[5] = in_now[5] + robert_filter_coeff * (in_new[5] - 2.0 * in_now[5] + in_old[5])\n    in_now[6] = in_now[6] + robert_filter_coeff * (in_new[6] - 2.0 * in_now[6] + in_old[6])\n\n    out_old[:] = in_now\n    out_now[:] = in_new\n    return nothing\n\nend","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Two key differences:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"forward_func_4_AD now returns nothing, but is rather a function of both its input and output.\nAll operations are now inlined, meaning we compute the entries of the input vector individually.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Currently, Enzyme does not have compatibility with matrix/vector operations so inlining is necessary to run Enzyme on this function.","category":"page"},{"location":"generated/box/#Example-1:-Simply-using-Enzyme","page":"Box model","title":"Example 1: Simply using Enzyme","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"For the first example let's just compute the gradient of our forward function and examine the output. We'll just run the model for one step, and take a dt of ten days. The initial conditions of the system are given as Tbar and Sbar.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"const Tbar = [20.0; 1.0; 1.0]\nconst Sbar = [35.5; 34.5; 34.5]\n\n# Running the model one step forward\nstates_smooth, states_unsmooth = forward_func(copy([Tbar; Sbar]), copy([Tbar; Sbar]), 10*day, 1)\n\n# Run Enzyme one time on `forward_func_4_AD``\ndin_now = zeros(6)\ndin_old = zeros(6)\nout_now = zeros(6); dout_now = ones(6)\nout_old = zeros(6); dout_old = ones(6)\nautodiff(forward_func_4_AD, Duplicated([Tbar; Sbar], din_now), Duplicated([Tbar; Sbar], din_old),\n                    Duplicated(out_now, dout_now), Duplicated(out_old, dout_old));\nnothing #hide","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"In order to run Enzyme on forward_func_4_AD, we've needed to provide quite a few placeholders, and wrap everything in Duplicated as all components of our function are vectors, not scalars. Let's go through and see what Enzyme did with all of those placeholders.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"First we can look at what happened to the zero vectors outnow and outold:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show out_now, out_old","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Comparing to the results of forward func:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show states_smooth[2], states_unsmooth[2]","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"we see that Enzyme has computed and stored exactly the output of the forward step. Next, let's look at din_now:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show din_now","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Just a few numbers, but this is what makes AD so nice: Enzyme has exactly computed the derivative of all outputs with respect to the input innow, evaluated at innow, and acted with this gradient on what we gave as dout_now (in our case, all ones). In math language, this is just","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"textdin now = (fracpartial textout now(textin now)partial textin now + fracpartial textout old(textin now)partial textin now) textdout now","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"We note here that had we given doutnow and doutnow as something else, our results will change. Let's multiply them by two and see what happens.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"din_now_new = zeros(6)\ndin_old_new = zeros(6)\nout_now = zeros(6); dout_now = 2*ones(6)\nout_old = zeros(6); dout_old = 2*ones(6)\nautodiff(forward_func_4_AD, Duplicated([Tbar; Sbar], din_now_new), Duplicated([Tbar; Sbar], din_old_new),\n                    Duplicated(out_now, dout_now), Duplicated(out_old, dout_old));\nnothing #hide","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Now checking dinnownew and dinoldnew we see","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show din_now_new","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"What happened? Enzyme is actually taking the computed gradient and acting on what we give as input to doutnow and doutold. Checking this, we see","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show 2*din_now","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"and they match the new results.","category":"page"},{"location":"generated/box/#Example-2:-Full-sensitivity-calculations","page":"Box model","title":"Example 2: Full sensitivity calculations","text":"","category":"section"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Now we want to use Enzyme for a bit more than just a single derivative. Let's say we'd like to understand how sensitive the final temperature of Box One is to the initial salinity of Box Two. That is, given the function","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"J = (100000)^T cdot mathbfx(t_f)","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"we want Enzyme to calculate the derivative","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"fracpartial Jpartial mathbfx(0)","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"where x(t)is the state of the model at time t. If we think aboutx(t_f)`` as solely depending on the initial condition, then this derivative is really","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"fracpartial Jpartial mathbfx(0) = fracpartialpartial mathbfx(0) left( (100000)^T cdot L(ldots(L(mathbfx(0)))) right)","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"with L(x(t)) = x(t + dt), i.e. one forward step. One could expand this derivative with the chain rule (and it would be very complicated), but really this is where Enzyme comes in. Each run of autodiff on our forward function is one piece of this big chain rule done for us! We also note that the chain rule goes from the outside in, so we start with the derivative of the forward function at the final state, and work backwards until the initial state. To get Enzyme to do this, we complete the following steps:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Run the forward model and store outputs (in a real ocean model this wouldn't be    feasible and we'd need to use checkpointing)\nCompute the initial derivative from the final state\nUse Enzyme to work backwards until we reach the desired derivative.","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"For simplicity we define a function that takes completes our AD steps","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"function ad_calc(in_now, in_old, M)\n\ndout_old = [1.0;0.0;0.0;0.0;0.0;0.0]\ndout_now = [0.0;0.0;0.0;0.0;0.0;0.0]\n\nfor j = M:-1:1\n\n    din_now = zeros(6)\n    din_old = zeros(6)\n\n    autodiff(forward_func_4_AD, Duplicated(in_now[j], din_now),\n            Duplicated(in_old[j], din_old), Duplicated(zeros(6), dout_old),\n            Duplicated(zeros(6), dout_now))\n\n    dout_old = copy(din_old)\n    dout_now = copy(din_now)\n\n    if j == 1\n        return din_now, din_old\n    end\n\nend\n\nend","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"First we complete step one and run the forward model:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"const M = 10000             ## Deciding on total number of forward steps to take\n\nstates_smooth, states_unsmooth = forward_func(copy([Tbar; Sbar]), copy([Tbar; Sbar]), 10*day, M);\nnothing #hide","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Next, we pass all of our states to the AD function to get back to the desired derivative:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"adjoint_now, adjoint_old = ad_calc(states_unsmooth, states_smooth, M);\nnothing #hide","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"And we're done! We were interested in sensitivity to the initial salinity of box two, which will live in what we've called adjoint_old. Checking this value we see","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show adjoint_old[5]","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"As it stands this is just a number, but a good check that Enzyme has computed what we want is to approximate the derivative with a Taylor series. Specifically,","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"J(mathbfx(0) + varepsilon) approx J(mathbfx(0)) +\nvarepsilon fracpartial Jpartial mathbfx(0)","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"and a simple rearrangement yields","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"fracpartial Jpartial mathbfx(0) approx\nfracJ(mathbfx(0) + varepsilon)  - J(mathbfx(0))varepsilon","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Hopefully we see that the analytical values converge close to the one we found with Enzyme:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"# unperturbed final state\nuse_to_check = states_smooth[M+1]\n\n# a loop to compute the perturbed final state\ndiffs = []\nstep_sizes = [1e-1, 1e-2, 1e-3, 1e-4, 1e-5, 1e-6, 1e-7, 1e-8, 1e-9, 1e-10]\nfor eps in step_sizes\n    new1 = Tbar\n    new2 = Sbar + [0.0;eps;0.0]\n    state_old = [new1; new2];\n    state_new = zeros(6);\n    state_now = [Tbar; Sbar];\n\n    for t = 1:M\n\n        rho_now = rho_func(state_now)\n        u_now = U_func(rho_now)\n        state_new = timestep_func(state_now, state_old, u_now, 10*day)\n\n        for j = 1:6\n            state_now[j] = state_now[j] + robert_filter_coeff * (state_new[j] - 2.0 * state_now[j] + state_old[j])\n        end\n\n        state_old = state_now\n        state_now = state_new\n\n\n    end\n\n    temp = (state_old[1] - use_to_check[1])/eps;\n    push!(diffs, temp)\n\nend","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"Then checking what we found the derivative to be analytically:","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show diffs","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"which comes very close to our calculated value. We can go further and check the percent difference to see","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"@show abs.(diffs .- adjoint_old[5])./adjoint_old[5]","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"and we get down to a percent difference on the order of 1e^-5, showing Enzyme calculated the correct derivative. Success!","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"","category":"page"},{"location":"generated/box/","page":"Box model","title":"Box model","text":"This page was generated using Literate.jl.","category":"page"},{"location":"","page":"Home","title":"Home","text":"CurrentModule = Enzyme","category":"page"},{"location":"#Enzyme","page":"Home","title":"Enzyme","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"Documentation for Enzyme.jl, the Julia bindings for Enzyme.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Enzyme performs automatic differentiation (AD) of statically analyzable LLVM. It is highly-efficient and its ability perform AD on optimized code allows Enzyme to meet or exceed the performance of state-of-the-art AD tools.","category":"page"},{"location":"","page":"Home","title":"Home","text":"Enzyme.jl can be installed in the usual way Julia packages are installed:","category":"page"},{"location":"","page":"Home","title":"Home","text":"] add Enzyme","category":"page"},{"location":"","page":"Home","title":"Home","text":"The Enzyme binary dependencies will be installed automatically via Julia's binary actifact system.","category":"page"},{"location":"","page":"Home","title":"Home","text":"The Enzyme.jl API revolves around the function autodiff, see it's documentation for details and a usage example. Also see Implementing pullbacks on how to use Enzyme.jl to implement back-propagation for functions with non-scalar results.","category":"page"},{"location":"#Caveats-/-Known-issues","page":"Home","title":"Caveats / Known-issues","text":"","category":"section"},{"location":"#Activity-of-temporary-storage","page":"Home","title":"Activity of temporary storage","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"If you have pass any temporary storage which may be involved in an active computation to a function you want to differentiate, you must also pass in a duplicated temporary storage for use in computing the derivatives. ","category":"page"},{"location":"","page":"Home","title":"Home","text":"function f(x, tmp, n)\n   tmp[1] = 1\n   for i in 1:n\n\t   tmp[1] *= x\n   end\n   tmp[1]\nend\n\n# Incorrect [ returns (0.0,) ]\nEnzyme.autodiff(f, Active(1.2), Const(Vector{Float64}(undef, 1)), Const(5))\n\n# Correct [ returns (10.367999999999999,) == 1.2^4 * 5 ]\nEnzyme.autodiff(f, Active(1.2), Duplicated(Vector{Float64}(undef, 1), Vector{Float64}(undef, 1)), Const(5))","category":"page"},{"location":"#CUDA.jl-support","page":"Home","title":"CUDA.jl support","text":"","category":"section"},{"location":"","page":"Home","title":"Home","text":"CUDA.jl is only support on Julia v1.7.0 and onwards. On 1.6 attempting to differentiate CUDA kernel functions, will not use device overloads correctly and thus return fundamentally wrong results.","category":"page"}]
}
